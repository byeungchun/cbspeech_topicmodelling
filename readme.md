# A primer on large language models for economists: structuring unstructured text data

## Overview
This notebook serves as an example application of the principles discussed in *A Primer on Large Language Models for Economists*. It demonstrates how **Large Language Models (LLMs)** and topic modeling can structure unstructured text data for economic analysis. By processing textual data, the notebook identifies themes and extracts topics that characterize the dataset, showcasing how complex, unstructured text can be transformed into structured insights relevant to economic research.

Designed with economists and central bankers in mind, this example application uses **LLMs**, **Topic modelling**, and **NLP libraries** such as **scikit-learn** and **gensim** to implement a topic model. This approach illustrates how LLM techniques, discussed in the paper, enable researchers to go beyond numerical data, adding depth through sentiment analysis, policy surveillance, and other econometric applications. The notebook is a practical demonstration, aiming to provide researchers with a foundational guide to efficiently use LLMs for structuring and analyzing textual data in economics.

## How to Execute the Notebook on Google Colab Using GPU
To run this notebook on Google Colab with GPU support:
1. Open the notebook and click on the provided **Google Colab link**.
2. In Colab, navigate to **Runtime > Change runtime type**.
3. Set **Hardware accelerator** to **GPU** and save.
4. Ensure the necessary libraries (e.g., `scikit-learn`, `gensim`) are installed within the Colab environment.
5. Execute each cell sequentially, following any instructions provided for data loading and preprocessing.


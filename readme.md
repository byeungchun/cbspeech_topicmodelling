# 🌐 A Primer on Large Language Models for Economists: Structuring Unstructured Text Data

## 📘 Overview
This notebook is an **example application** of the key concepts presented in *A Primer on Large Language Models for Economists*. It showcases how **Large Language Models (LLMs)** and **topic modeling** can bring structure to unstructured text data for economic analysis. Through processing textual data, this notebook identifies underlying themes and extracts topics that characterize the dataset, transforming complex, unstructured text into structured, actionable insights for economic research.

Tailored for **economists and central bankers**, this example utilizes **LLMs**, **topic modeling**, and **NLP libraries** such as **scikit-learn** and **gensim** to build a topic model. The approach exemplifies how LLM techniques—outlined in the paper—extend analysis beyond numerical data, offering applications in **sentiment analysis**, **policy surveillance**, and more, enriching econometric insights. This notebook serves as a hands-on guide for researchers looking to harness LLMs effectively for structuring and analyzing textual data in economics.

## 🚀 Running the Notebook on Google Colab with GPU Support
To take advantage of GPU acceleration in Google Colab for faster processing, follow these steps:
1. **Open the notebook** via the provided **Google Colab link**.
2. In Colab, go to **Runtime > Change runtime type**.
3. Set the **Hardware accelerator** to **GPU** and click **Save**.
4. Install any necessary libraries (e.g., `scikit-learn`, `gensim`) within the Colab environment if prompted.
5. **Run each cell sequentially**, following any specific instructions for loading and preprocessing data.
